{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecção de plágio, Engenharia de recursos\n",
    "\n",
    "Neste projeto, você terá a tarefa de construir um detector de plágio que examina um arquivo de texto de resposta e executa a classificação binária; rotular esse arquivo como plagiado ou não, dependendo da semelhança do arquivo de texto com o texto fonte fornecido.\n",
    "\n",
    "Sua primeira tarefa será criar alguns recursos que podem ser usados ​​para treinar um modelo de classificação. Esta tarefa será dividida em algumas etapas discretas:\n",
    "\n",
    "* Limpe e pré-processe os dados.\n",
    "* Defina recursos para comparar a semelhança de um texto de resposta e um texto de origem e extraia recursos de semelhança.\n",
    "* Selecione recursos \"bons\", analisando as correlações entre os diferentes recursos.\n",
    "* Crie arquivos `.csv` de treinamento / teste que contenham os recursos relevantes e rótulos de classe para pontos de dados de treinamento / teste.\n",
    "\n",
    "No _next_ notebook, Notebook 3, você usará os recursos e os arquivos `.csv` que você criar _neste_ notebook para treinar um modelo de classificação binária em uma instância de notebook SageMaker.\n",
    "\n",
    "Você definirá alguns recursos de similaridade diferentes, conforme descrito [neste artigo](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/development-a-corpus-of-plagiarized-short-answers.pdf), que deve ajudá-lo a construir um detector de plágio robusto!\n",
    "\n",
    "Para completar este caderno, você terá que completar todos os exercícios dados e responder a todas as perguntas neste caderno.\n",
    "> Todas as suas tarefas serão claramente rotuladas como ** EXERCÍCIO ** e as perguntas como ** QUESTION **.\n",
    "\n",
    "Caberá a você decidir sobre os recursos a serem incluídos em seus dados finais de treinamento e teste.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Leitura dos dados\n",
    "\n",
    "A célula abaixo irá baixar os dados do projeto necessários e extrair os arquivos para a pasta `data /`.\n",
    "\n",
    "Esses dados são uma versão ligeiramente modificada de um conjunto de dados criado por Paul Clough (Estudos de Informação) e Mark Stevenson (Ciência da Computação), na Universidade de Sheffield. Você pode ler tudo sobre a coleta de dados e corpus, em [their university webpage](https://ir.shef.ac.uk/cloughie/resources/plagiarism_corpus.html). \n",
    "\n",
    "> **Citation for data**: Clough, P. and Stevenson, M. Developing A Corpus of Plagiarised Short Answers, Language Resources and Evaluation: Special Issue on Plagiarism and Authorship Analysis, In Press. [Download]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n",
      "'unzip' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# NOTE:\n",
    "# you only need to run this cell if you have not yet downloaded the data\n",
    "# otherwise you may skip this cell or comment it out\n",
    "\n",
    "!wget https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c4147f9_data/data.zip\n",
    "!unzip data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este conjunto de dados de plágio é composto de vários arquivos de texto; cada um desses arquivos tem características que são resumidas em um arquivo `.csv` chamado` file_information.csv`, que podemos ler usando `pandas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>cut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>heavy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>non</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task Category\n",
       "0  g0pA_taska.txt    a      non\n",
       "1  g0pA_taskb.txt    b      cut\n",
       "2  g0pA_taskc.txt    c    light\n",
       "3  g0pA_taskd.txt    d    heavy\n",
       "4  g0pA_taske.txt    e      non"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file = 'data/file_information.csv'\n",
    "plagiarism_df = pd.read_csv(csv_file)\n",
    "\n",
    "# print out the first few rows of data info\n",
    "plagiarism_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de plágio\n",
    "\n",
    "Cada arquivo de texto está associado a uma **Task** (tarefa A-E) e uma **Categoria** de plágio, que você pode ver no DataFrame acima.\n",
    "\n",
    "### Tarefas, A-E\n",
    "\n",
    "Cada arquivo de texto contém uma resposta a uma pergunta curta; essas perguntas são rotuladas como tarefas A-E. Por exemplo, a Tarefa A faz a pergunta: \"O que é herança na programação orientada a objetos?\"\n",
    "\n",
    "### Categorias de plágio\n",
    "\n",
    "Cada arquivo de texto tem um rótulo / categoria de plágio associado:\n",
    "\n",
    "**1. Plagiarized categories: `cut`, `light`, and `heavy`.**\n",
    "* These categories represent different levels of plagiarized answer texts. `cut` answers copy directly from a source text, `light` answers are based on the source text but include some light rephrasing, and `heavy` answers are based on the source text, but *heavily* rephrased (and will likely be the most challenging kind of plagiarism to detect).\n",
    "     \n",
    "**2. Non-plagiarized category: `non`.** \n",
    "* `non` indicates that an answer is not plagiarized; the Wikipedia source text is not used to create this answer.\n",
    "    \n",
    "**3. Special, source text category: `orig`.**\n",
    "* This is a specific category for the original, Wikipedia source text. We will use these files only for comparison purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Pré-processar os dados\n",
    "\n",
    "Nas próximas células, você terá a tarefa de criar um novo DataFrame com as informações desejadas sobre todos os arquivos no diretório `data /`. Isso irá preparar os dados para extração de recursos e para treinar um classificador de plágio binário."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXERCÍCIO: Converta dados categóricos em numéricos\n",
    "\n",
    "Você notará que a coluna `Categoria` nos dados contém strings ou valores categóricos e, para prepará-los para extração de recursos, queremos convertê-los em valores numéricos. Além disso, nosso objetivo é criar um classificador binário e, portanto, precisaremos de um rótulo de classe binária que indique se um texto de resposta foi plagiado (1) ou não (0). Complete a função abaixo `numerical_dataframe` que lê em um arquivo` file_information.csv` por nome e retorna um *novo* DataFrame com uma coluna numérica `Category` e uma nova coluna` Class` que rotula cada resposta como plagiada ou não.\n",
    "\n",
    "Sua função deve retornar um novo DataFrame com as seguintes propriedades:\n",
    "\n",
    "* 4 colunas: `File`,` Task`, `Category`,` Class`. As colunas `File` e` Task` podem permanecer inalteradas do arquivo `.csv` original.\n",
    "* Converta todos os rótulos de `Categoria` em rótulos numéricos de acordo com as seguintes regras (um valor mais alto indica um grau mais alto de plágio):\n",
    "    * 0 = `non`\n",
    "    * 1 = `heavy`\n",
    "    * 2 = `light`\n",
    "    * 3 = `cut`\n",
    "    * -1 = `orig`, este é um valor especial que indica um arquivo original.\n",
    "* Para a nova coluna `Class`\n",
    "    * Qualquer texto de resposta que não seja plagiado (`não`) deve ter o rótulo de classe` 0`.\n",
    "    * Qualquer texto de resposta plagiado deve ter o rótulo de classe `1`.\n",
    "    * E qualquer texto ʻorig` terá um rótulo especial `-1`.\n",
    "\n",
    "### Saída esperada\n",
    "\n",
    "Depois de executar sua função, você deve obter um DataFrame com linhas que se parecem com o seguinte:\n",
    "\n",
    "```\n",
    "\n",
    "        File\t     Task  Category  Class\n",
    "0\tg0pA_taska.txt\ta\t  0   \t0\n",
    "1\tg0pA_taskb.txt\tb\t  3   \t1\n",
    "2\tg0pA_taskc.txt\tc\t  2   \t1\n",
    "3\tg0pA_taskd.txt\td\t  1   \t1\n",
    "4\tg0pA_taske.txt\te\t  0\t   0\n",
    "...\n",
    "...\n",
    "99   orig_taske.txt    e     -1      -1\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a csv file and return a transformed dataframe\n",
    "def numerical_dataframe(csv_file='data/file_information.csv'):\n",
    "    '''Reads in a csv file which is assumed to have `File`, `Category` and `Task` columns.\n",
    "       This function does two things: \n",
    "       1) converts `Category` column values to numerical values \n",
    "       2) Adds a new, numerical `Class` label column.\n",
    "       The `Class` column will label plagiarized answers as 1 and non-plagiarized as 0.\n",
    "       Source texts have a special label, -1.\n",
    "       :param csv_file: The directory for the file_information.csv file\n",
    "       :return: A dataframe with numerical categories and a new `Class` label column'''\n",
    "    \n",
    "    # Reads a csv file\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Converts `Category` column values to numerical values \n",
    "    df.loc[df.Category == 'non', 'Category'] = \"0\"\n",
    "    df.loc[df.Category == 'heavy', 'Category'] = \"1\"\n",
    "    df.loc[df.Category == 'light', 'Category'] = \"2\"\n",
    "    df.loc[df.Category == 'cut', 'Category'] = \"3\"\n",
    "    df.loc[df.Category == 'orig', 'Category'] = \"-1\"\n",
    "    \n",
    "    df.Category = df.Category.astype('int64')\n",
    "    \n",
    "    # Adds a new, numerical Class label column.\n",
    "    df['Class'] = 1\n",
    "    df.loc[df.Category == 0, 'Class'] = 0\n",
    "    df.loc[df.Category == -1, 'Class'] = -1\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Células de teste\n",
    "\n",
    "Abaixo estão algumas células de teste. O primeiro é um teste informal onde você pode verificar se seu código está funcionando conforme o esperado, chamando sua função e imprimindo o resultado retornado.\n",
    "\n",
    "A **segunda** célula abaixo é uma célula de teste mais rigorosa. O objetivo de uma célula como essa é garantir que seu código esteja funcionando conforme o esperado e formar quaisquer variáveis que possam ser usadas nos testes / código _mais tarde_, neste caso, o quadro de dados, `transform_df`.\n",
    "\n",
    "> As células neste bloco de notas devem ser executadas em ordem cronológica (a ordem em que aparecem no bloco de notas). Isso é especialmente importante para células de teste.\n",
    "\n",
    "Freqüentemente, as células posteriores dependem das funções, importações ou variáveis definidas nas células anteriores. Por exemplo, alguns testes dependem de testes anteriores para funcionar.\n",
    "\n",
    "Esses testes não testam todos os casos, mas são uma ótima maneira de verificar se você está no caminho certo!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0\n",
       "5  g0pB_taska.txt    a         0      0\n",
       "6  g0pB_taskb.txt    b         0      0\n",
       "7  g0pB_taskc.txt    c         3      1\n",
       "8  g0pB_taskd.txt    d         2      1\n",
       "9  g0pB_taske.txt    e         1      1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# informal testing, print out the results of a called function\n",
    "# create new `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "# check that all categories of plagiarism have a class label = 1\n",
    "transformed_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n",
      "\n",
      "Example data: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class\n",
       "0  g0pA_taska.txt    a         0      0\n",
       "1  g0pA_taskb.txt    b         3      1\n",
       "2  g0pA_taskc.txt    c         2      1\n",
       "3  g0pA_taskd.txt    d         1      1\n",
       "4  g0pA_taske.txt    e         0      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test cell that creates `transformed_df`, if tests are passed\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "# importing tests\n",
    "import problem_unittests as tests\n",
    "\n",
    "# test numerical_dataframe function\n",
    "tests.test_numerical_df(numerical_dataframe)\n",
    "\n",
    "# if above test is passed, create NEW `transformed_df`\n",
    "transformed_df = numerical_dataframe(csv_file ='data/file_information.csv')\n",
    "\n",
    "# check work\n",
    "print('\\nExample data: ')\n",
    "transformed_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento de texto e divisão de dados\n",
    "\n",
    "Lembre-se de que o objetivo deste projeto é construir um classificador de plágio. Em sua essência, essa tarefa é um texto de comparação; aquele que analisa uma determinada resposta e um texto de origem, os compara e prevê se uma resposta foi plagiada da fonte. Para fazer essa comparação de maneira eficaz e treinar um classificador, precisaremos fazer mais algumas coisas: pré-processar todos os nossos dados de texto e preparar os arquivos de texto (neste caso, os 95 arquivos de resposta e 5 arquivos de origem originais) para ser facilmente comparada e dividir nossos dados em um conjunto de `treinar` e` teste` que pode ser usado para treinar um classificador e avaliá-lo, respectivamente.\n",
    "\n",
    "Para este fim, você recebeu um código que adiciona informações adicionais ao seu `transform_df` acima. As próximas duas células não precisam ser alteradas; eles adicionam duas colunas adicionais ao `transform_df`:\n",
    "\n",
    "1. Uma coluna de `Texto`; isto contém todo o texto em minúsculas para um `Arquivo`, com pontuação estranha removida.\n",
    "2. Uma coluna `Datatype`; este é um valor de string `train`,` test` ou `orig` que rotula um ponto de dados como parte de nosso trem ou conjunto de teste\n",
    "\n",
    "Os detalhes de como essas colunas adicionais são criadas podem ser encontrados no arquivo `helpers.py` no diretório do projeto. Você é encorajado a ler esse arquivo para ver exatamente como o texto é processado e como os dados são divididos.\n",
    "\n",
    "Execute as células abaixo para obter um `complete_df` que contém todas as informações de que você precisa para prosseguir com a detecção de plágio e a engenharia de recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "\n",
       "                                                Text  \n",
       "0  inheritance is a basic concept of object orien...  \n",
       "1  pagerank is a link analysis algorithm used by ...  \n",
       "2  the vector space model also called term vector...  \n",
       "3  bayes theorem was names after rev thomas bayes...  \n",
       "4  dynamic programming is an algorithm design tec...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers \n",
    "\n",
    "# create a text column \n",
    "text_df = helpers.create_text_column(transformed_df)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample processed text:\n",
      "\n",
      " inheritance is a basic concept of object oriented programming where the basic idea is to create new classes that add extra detail to existing classes this is done by allowing the new classes to reuse the methods and variables of the existing classes and new methods and classes are added to specialise the new class inheritance models the is kind of relationship between entities or objects  for example postgraduates and undergraduates are both kinds of student this kind of relationship can be visualised as a tree structure where student would be the more general root node and both postgraduate and undergraduate would be more specialised extensions of the student node or the child nodes  in this relationship student would be known as the superclass or parent class whereas  postgraduate would be known as the subclass or child class because the postgraduate class extends the student class  inheritance can occur on several layers where if visualised would display a larger tree structure for example we could further extend the postgraduate node by adding two extra extended classes to it called  msc student and phd student as both these types of student are kinds of postgraduate student this would mean that both the msc student and phd student classes would inherit methods and variables from both the postgraduate and student classes  \n"
     ]
    }
   ],
   "source": [
    "# after running the cell above\n",
    "# check out the processed text for a single file, by row index\n",
    "row_idx = 0 # feel free to change this index\n",
    "\n",
    "sample_text = text_df.iloc[0]['Text']\n",
    "\n",
    "print('Sample processed text:\\n\\n', sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divida os dados em conjuntos de treinamento e teste\n",
    "\n",
    "A próxima célula adicionará uma coluna `Datatype` a um determinado DataFrame para indicar se o registro é:\n",
    "* `train` - Dados de treinamento, para treinamento de modelo.\n",
    "* `test` - Dados de teste, para avaliação do modelo.\n",
    "* `orig` - A resposta original da tarefa da wikipedia.\n",
    "\n",
    "### Amostragem estratificada\n",
    "\n",
    "O código fornecido usa uma função auxiliar que você pode ver no arquivo `helpers.py` no diretório principal do projeto. Isso implementa [amostragem aleatória estratificada] (https://en.wikipedia.org/wiki/Stratified_sampling) para dividir dados aleatoriamente por tarefa e quantidade de plágio. A amostragem estratificada garante que recebamos dados de treinamento e teste que sejam distribuídos de maneira bastante uniforme nas combinações de tarefas e plágio. Aproximadamente 26% dos dados são armazenados para teste e 74% dos dados são usados ​​para treinamento.\n",
    "\n",
    "A função **train_test_dataframe** leva em um DataFrame que assume ter as colunas `Tarefa` e` Categoria`, e retorna um quadro modificado que indica em qual `Tipo de dados` (trem, teste ou origem) um arquivo cai. Esta amostra mudará ligeiramente com base em * random_seed *. Devido ao pequeno tamanho da amostra, essa amostragem aleatória estratificada fornecerá resultados mais estáveis ​​para um classificador de plágio binário. A estabilidade aqui é menor * variação * na precisão do classificador, dada uma semente aleatória."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File</th>\n",
       "      <th>Task</th>\n",
       "      <th>Category</th>\n",
       "      <th>Class</th>\n",
       "      <th>Text</th>\n",
       "      <th>Datatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g0pA_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept of object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>g0pA_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>pagerank is a link analysis algorithm used by ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>g0pA_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>the vector space model also called term vector...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>g0pA_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem was names after rev thomas bayes...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>g0pA_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>dynamic programming is an algorithm design tec...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>g0pB_taska.txt</td>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>inheritance is a basic concept in object orien...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>g0pB_taskb.txt</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pagerank pr refers to both the concept and the...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>g0pB_taskc.txt</td>\n",
       "      <td>c</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>vector space model is an algebraic model for r...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>g0pB_taskd.txt</td>\n",
       "      <td>d</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>bayes theorem relates the conditional and marg...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>g0pB_taske.txt</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>dynamic programming is a method for solving ma...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             File Task  Category  Class  \\\n",
       "0  g0pA_taska.txt    a         0      0   \n",
       "1  g0pA_taskb.txt    b         3      1   \n",
       "2  g0pA_taskc.txt    c         2      1   \n",
       "3  g0pA_taskd.txt    d         1      1   \n",
       "4  g0pA_taske.txt    e         0      0   \n",
       "5  g0pB_taska.txt    a         0      0   \n",
       "6  g0pB_taskb.txt    b         0      0   \n",
       "7  g0pB_taskc.txt    c         3      1   \n",
       "8  g0pB_taskd.txt    d         2      1   \n",
       "9  g0pB_taske.txt    e         1      1   \n",
       "\n",
       "                                                Text Datatype  \n",
       "0  inheritance is a basic concept of object orien...    train  \n",
       "1  pagerank is a link analysis algorithm used by ...     test  \n",
       "2  the vector space model also called term vector...    train  \n",
       "3  bayes theorem was names after rev thomas bayes...    train  \n",
       "4  dynamic programming is an algorithm design tec...    train  \n",
       "5  inheritance is a basic concept in object orien...    train  \n",
       "6  pagerank pr refers to both the concept and the...    train  \n",
       "7  vector space model is an algebraic model for r...     test  \n",
       "8  bayes theorem relates the conditional and marg...    train  \n",
       "9  dynamic programming is a method for solving ma...     test  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 1 # can change; set for reproducibility\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import helpers\n",
    "\n",
    "# create new df with Datatype (train, test, orig) column\n",
    "# pass in `text_df` from above to create a complete dataframe, with all the information you need\n",
    "complete_df = helpers.train_test_dataframe(text_df, random_seed=random_seed)\n",
    "\n",
    "# check results\n",
    "complete_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determinando o plágio\n",
    "\n",
    "Agora que você preparou esses dados e criou um `complete_df` de informações, incluindo o texto e a classe associada a cada arquivo, você pode prosseguir para a tarefa de extrair recursos de similaridade que serão úteis para classificação de plágio.\n",
    "\n",
    "> Nota: Os exercícios de código a seguir, assumem que o `complete_df` como existe agora, ** não ** terá suas colunas existentes modificadas.\n",
    "\n",
    "O `complete_df` deve sempre incluir as colunas:` ['Arquivo', 'Tarefa', 'Categoria', 'Classe', 'Texto', 'Tipo de dados'] `. Você pode adicionar colunas adicionais e criar quaisquer novos DataFrames de que precisar, copiando as partes do `complete_df`, desde que você não modifique os valores existentes diretamente.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursos de similaridade\n",
    "\n",
    "Uma das maneiras de detectar o plágio é computar **recursos de similaridade** que medem o quão semelhante um determinado texto de resposta é em comparação com o texto original da Wikipedia (para uma tarefa específica, a-e). Os recursos de similaridade que você usará são informados por [este artigo sobre detecção de plágio](https://s3.amazonaws.com/video.udacity-data.com/topher/2019/January/5c412841_developing-a-corpus-of-plagiarised-short-answers/development-a-corpus-of-plagiarized-short-answers.pdf).\n",
    "> Neste artigo, os pesquisadores criaram recursos chamados **contenção** e **mais longa subsequência comum**.\n",
    "\n",
    "Usando esses recursos como entrada, você treinará um modelo para distinguir entre texto plagiado e não plagiado\n",
    "\n",
    "## Engenharia de Recursos\n",
    "\n",
    "Vamos falar um pouco mais sobre os recursos que queremos incluir em um modelo de detecção de plágio e como calcular esses recursos. Nas explicações a seguir, vou me referir a um arquivo de texto enviado como **Texto de resposta do aluno (A)** e ao arquivo-fonte original da Wikipédia (com o qual queremos comparar essa resposta) como **Texto-fonte da Wikipédia (S)**.\n",
    "\n",
    "### Contenção\n",
    "\n",
    "Sua primeira tarefa será criar **recursos de contenção**. Para entender a contenção, vamos primeiro revisitar uma definição de [n-gramas] (https://en.wikipedia.org/wiki/N-gram). Um * n-grama * é um agrupamento de palavras sequencial. Por exemplo, em uma linha como \"a regra de bayes nos dá uma maneira de combinar conhecimento prévio com novas informações\", um 1 grama é apenas uma palavra, como \"bayes\". Um de 2 gramas pode ser \"regra de bayes\" e um de 3 gramas pode ser \"combinar conhecimento prévio\".\n",
    "\n",
    "> A contenção é definida como a **interseção** da contagem de palavras de n-gramas do Texto-fonte da Wikipedia (S) com a contagem de palavras de n-gramas do Texto de resposta do aluno (S) *dividido* pela palavra de n-gramas contagem do Texto de Resposta do Aluno.\n",
    "\n",
    "$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "\n",
    "Se os dois textos não tiverem n-gramas em comum, a contenção será 0, mas se _todos_ seus n-gramas se cruzarem, a contenção será 1. Intuitivamente, você pode ver como ter n-gramas mais longos em comum pode ser um indicação de plágio cut-and-paste. Neste projeto, caberá a você decidir sobre o `n` apropriado ou vários` n`s para usar em seu modelo final.\n",
    "\n",
    "\n",
    "### EXERCÍCIO: Crie recursos de contenção\n",
    "\n",
    "Dado o `complete_df` que você criou, você deve ter todas as informações de que precisa para comparar qualquer Texto de Resposta do Aluno (A) com seu Texto Fonte da Wikipedia (S) apropriado. Uma resposta para a tarefa A deve ser comparada ao texto-fonte para a tarefa A, assim como as respostas para as tarefas B, C, D e E devem ser comparadas com o texto-fonte original correspondente.\n",
    "\n",
    "Neste exercício, você completará a função `calcular_contenção`, que calcula a contenção com base nos seguintes parâmetros:\n",
    "* Um determinado DataFrame, `df` (que é considerado o` complete_df` acima)\n",
    "* Um ʻanswer_filename`, como 'g0pB_taskd.txt'\n",
    "* Um comprimento de n-grama, `n`\n",
    "\n",
    "### Cálculo de contenção\n",
    "\n",
    "As etapas gerais para completar esta função são as seguintes:\n",
    "1. De *todos* os arquivos de texto em um determinado `df`, crie um array de contagens de n-gramas; sugere-se que você use um [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) para essa finalidade.\n",
    "2. Obtenha a resposta processada e os textos de origem para o ʻanswer_filename` fornecido.\n",
    "3. Calcule a contenção entre uma resposta e o texto fonte de acordo com a seguinte equação.\n",
    "\n",
    "    >$$ \\frac{\\sum{count(\\text{ngram}_{A}) \\cap count(\\text{ngram}_{S})}}{\\sum{count(\\text{ngram}_{A})}} $$\n",
    "    \n",
    "4. Retorne esse valor de contenção.\n",
    "\n",
    "Recomendamos que você escreva quaisquer funções auxiliares de que precise para completar a função abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the ngram containment for one answer file/source file pair in a df\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def calculate_containment(df, n, answer_filename):\n",
    "    '''Calculates the containment between a given answer text and its associated source text.\n",
    "       This function creates a count of ngrams (of a size, n) for each text file in our data.\n",
    "       Then calculates the containment by finding the ngram count for a given answer text, \n",
    "       and its associated source text, and calculating the normalized intersection of those counts.\n",
    "       :param df: A dataframe with columns,\n",
    "           'File', 'Task', 'Category', 'Class', 'Text', and 'Datatype'\n",
    "       :param n: An integer that defines the ngram size\n",
    "       :param answer_filename: A filename for an answer text in the df, ex. 'g0pB_taskd.txt'\n",
    "       :return: A single containment value that represents the similarity\n",
    "           between an answer text and its source text.\n",
    "    '''\n",
    "\n",
    "    is_in_file = df.File == answer_filename\n",
    "    \n",
    "    text = df[is_in_file]['Text'].iloc[0]\n",
    "    task = df[is_in_file]['Task'].iloc[0]\n",
    "    \n",
    "    # Gets source text\n",
    "    is_task = df['Task'] == task\n",
    "    is_class_source = df['Class'] == -1\n",
    "    \n",
    "    source_text = df[is_task & is_class_source]['Text'].iloc[0]\n",
    "    \n",
    "    # Counts the ngrams\n",
    "    counts = CountVectorizer(analyzer='word', ngram_range=(n,n))\n",
    "    ngrams = counts.fit_transform([text, source_text]).toarray()\n",
    "    \n",
    "    # Calculates the containment\n",
    "    common_ngrams = sum(min(answer, source) for answer, source in zip(*ngrams))\n",
    "    ngrams_a = ngrams[0].sum()\n",
    "    \n",
    "    return common_ngrams / ngrams_a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Células de teste\n",
    "\n",
    "Depois de implementar a função de contenção, você pode testar seu comportamento.\n",
    "\n",
    "A célula abaixo itera através dos primeiros arquivos e calcula os valores originais da categoria _and_ de contenção para um n e arquivo especificado.\n",
    "\n",
    "> Se você implementou isso corretamente, verá que os não plagiados têm valores de contenção baixos ou próximos a 0 e que os exemplos plagiados têm valores de contenção mais altos, próximos a 1.\n",
    "\n",
    "Observe o que acontece quando você altera o valor de n. Eu recomendo aplicar seu código a vários arquivos e comparar os valores de contenção resultantes. Você deve ver que os valores de contenção mais altos correspondem aos arquivos com a categoria mais alta (`cut`) de nível de plágio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original category values: \n",
      " [0, 3, 2, 1, 0]\n",
      "\n",
      "3-gram containment values: \n",
      " [0.009345794392523364, 0.9641025641025641, 0.6136363636363636, 0.15675675675675677, 0.031746031746031744]\n"
     ]
    }
   ],
   "source": [
    "# select a value for n\n",
    "n = 3\n",
    "\n",
    "# indices for first few files\n",
    "test_indices = range(5)\n",
    "\n",
    "# iterate through files and calculate containment\n",
    "category_vals = []\n",
    "containment_vals = []\n",
    "for i in test_indices:\n",
    "    # get level of plagiarism for a given file index\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # calculate containment for given file and n\n",
    "    filename = complete_df.loc[i, 'File']\n",
    "    c = calculate_containment(complete_df, n, filename)\n",
    "    containment_vals.append(c)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print(str(n)+'-gram containment values: \\n', containment_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# run this test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test containment calculation\n",
    "# params: complete_df from before, and containment function\n",
    "tests.test_containment(complete_df, calculate_containment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PERGUNTA 1: Por que podemos calcular os recursos de contenção em *todos* os dados (treinamento e teste), antes de dividir o DataFrame para modelagem? Ou seja, o que acontece com o cálculo de contenção significa que os dados de teste e treinamento não influenciam um ao outro?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Subsequência Comum Mais Longa\n",
    "\n",
    "Contenção uma boa maneira de encontrar sobreposição no uso de palavras entre dois documentos; pode ajudar a identificar casos de cortar e colar, bem como níveis parafraseados de plágio. Como o plágio é uma tarefa bastante complexa, com níveis variados, geralmente é útil incluir outras medidas de similaridade. O artigo também discute um recurso chamado **mais longa subsequência comum**.\n",
    "\n",
    "> A subsequência comum mais longa é a sequência mais longa de palavras (ou letras) que são * iguais * entre o Texto-fonte da Wikipedia (S) e o Texto de Resposta do Aluno (A). Este valor também é normalizado dividindo-se pelo número total de palavras (ou letras) no Texto de Resposta do Aluno.\n",
    "\n",
    "Neste exercício, pediremos que você calcule a maior subsequência comum de palavras entre dois textos.\n",
    "\n",
    "### EXERCÍCIO: Calcule a maior subsequência comum\n",
    "\n",
    "Complete a função `lcs_norm_word`; isso deve calcular a * maior subsequência comum * de palavras entre um Texto de Resposta do Aluno e o Texto-fonte da Wikipedia correspondente.\n",
    "\n",
    "Pode ser útil pensar nisso como um exemplo concreto. Um problema de Longest Common Subsequence (LCS) pode ser o seguinte:\n",
    "* Dados dois textos: texto A (texto de resposta) de comprimento n, e string S (texto de origem original) de comprimento m. Nosso objetivo é produzir sua maior subsequência comum de palavras: a maior sequência de palavras que aparece da esquerda para a direita em ambos os textos (embora as palavras não precisem estar em ordem contínua).\n",
    "* Considere:\n",
    "    * A = \"acho que o pagerank é um algoritmo de análise de link usado pelo google que usa um sistema de pesos anexado a cada elemento de um conjunto de documentos com hiperlink\"\n",
    "    * S = \"pagerank é um algoritmo de análise de link usado pelo mecanismo de pesquisa do Google na Internet que atribui uma ponderação numérica a cada elemento de um conjunto de documentos com hiperlink\"\n",
    "\n",
    "* Neste caso, podemos ver que o início de cada frase de bastante semelhante, tendo sobreposição na sequência de palavras, \"pagerank é um algoritmo de análise de link usado por\" antes de divergir ligeiramente. Então, ** continuamos nos movendo da esquerda para a direita ao longo de ambos os textos ** até vermos a próxima sequência comum; neste caso, é apenas uma palavra, \"google\". Em seguida, encontramos \"aquele\" e \"a\" e, finalmente, a mesma terminação \"para cada elemento de um conjunto de documentos com hiperlink\".\n",
    "* Abaixo, fica uma visão clara de como essas sequências foram encontradas, sequencialmente, em cada texto.\n",
    "\n",
    "<img src='notebook_ims/common_subseq_words.png' width=40% />\n",
    "\n",
    "* Agora, essas palavras aparecem na ordem da esquerda para a direita em cada documento, sequencialmente, e mesmo que haja algumas palavras no meio, contamos isso como a maior subsequência comum entre os dois textos.\n",
    "* Se eu contar cada palavra que encontrei em comum, obtenho o valor 20. ** Então, LCS tem comprimento 20 **.\n",
    "* A seguir, para normalizar este valor, divida pelo comprimento total da resposta do aluno; neste exemplo, o comprimento é apenas 27. **Portanto, a função `lcs_norm_word` deve retornar o valor` 20 / 27` ou cerca de `0,7408`.**\n",
    "\n",
    "Dessa forma, LCS é um ótimo indicador de plágio de recortar e colar ou se alguém fez referência ao mesmo texto de origem várias vezes em uma resposta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LCS, programação dinâmica\n",
    "\n",
    "Se você ler o cenário acima, verá que esse algoritmo depende de olhar dois textos e compará-los palavra por palavra. Você pode resolver esse problema de várias maneiras. Primeiro, pode ser útil `.split ()` cada texto em listas de palavras separadas por vírgulas para comparar. Em seguida, você pode iterar por cada palavra nos textos e compará-los, aumentando seu valor para LCS à medida que avança.\n",
    "\n",
    "O método que recomendo para implementar um algoritmo LCS eficiente é: usando uma matriz e programação dinâmica. A **programação dinâmica** consiste em dividir um problema maior em um conjunto menor de subproblemas e construir um resultado completo sem ter que repetir nenhum subproblema.\n",
    "\n",
    "Esta abordagem pressupõe que você pode dividir uma grande tarefa LCS em uma combinação de tarefas LCS menores. Vejamos um exemplo simples que compara letras:\n",
    "\n",
    "* A = \"ABCD\"\n",
    "* S = \"BD\"\n",
    "\n",
    "Podemos ver imediatamente que a subsequência mais longa de _letters_ aqui é 2 (B e D estão em sequência em ambas as strings). E podemos calcular isso observando as relações entre cada letra nas duas strings, A e S.\n",
    "\n",
    "Aqui, eu tenho uma matriz com as letras de A no topo e as letras de S no lado esquerdo:\n",
    "\n",
    "\n",
    "<img src='notebook_ims/matrix_1.png' width=40% />\n",
    "\n",
    "Isso começa como uma matriz que tem tantas colunas e linhas quanto letras nas strings S e O ** + 1 ** linha e coluna adicionais, preenchidas com zeros nos lados superior e esquerdo. Portanto, neste caso, em vez de uma matriz 2x4 é uma matriz 3x5.\n",
    "\n",
    "Agora, podemos preencher essa matriz dividindo-a em problemas LCS menores. Por exemplo, vamos primeiro olhar para as substrings mais curtas: a letra inicial de A e S. Vamos primeiro perguntar, qual é a Subseqüência comum mais longa entre essas duas letras \"A\" e \"B\"?\n",
    "\n",
    "**Aqui, a resposta é zero e preenchemos a célula da grade correspondente com esse valor.**\n",
    "\n",
    "<img src='notebook_ims/matrix_2.png' width=30% />\n",
    "\n",
    "Em seguida, fazemos a próxima pergunta, qual é o LCS entre \"AB\" e \"B\"?\n",
    "\n",
    "**Aqui, temos uma correspondência e podemos preencher o valor apropriado 1.**\n",
    "\n",
    "<img src='notebook_ims/matrix_3_match.png' width=25% />\n",
    "\n",
    "Se continuarmos, chegaremos a uma matriz final que se parece com a seguinte, com um **2** no canto inferior direito.\n",
    "\n",
    "<img src='notebook_ims/matrix_6_complete.png' width=25% />\n",
    "\n",
    "O LCS final será aquele valor ** 2 ** * normalizado * pelo número de n-gramas em A. Portanto, nosso valor normalizado é 2/4 = **0,5**.\n",
    "\n",
    "### As regras da matriz\n",
    "\n",
    "Uma coisa a notar aqui é que você pode preencher esta matriz com eficiência, uma célula de cada vez. Cada célula da grade depende apenas dos valores nas células da grade que estão diretamente no topo e à esquerda dela ou na diagonal / canto superior esquerdo. As regras são as seguintes:\n",
    "* Comece com uma matriz que tenha uma linha e coluna extra de zeros.\n",
    "* À medida que você atravessa sua corda:\n",
    "     * Se houver uma correspondência, preencha a célula da grade com o valor no canto superior esquerdo da célula * mais * um. Portanto, em nosso caso, quando encontramos um B-B correspondente, adicionamos +1 ao valor no canto superior esquerdo da célula correspondente, 0.\n",
    "     * Se não houver uma correspondência, pegue o valor * máximo * diretamente para a célula esquerda ou superior e carregue esse valor para a célula sem correspondência.\n",
    "\n",
    "<img src='notebook_ims/matrix_rules.png' width=50% />\n",
    "\n",
    "Depois de preencher completamente a matriz, **a célula inferior direita manterá o valor LCS não normalizado**.\n",
    "\n",
    "Este tratamento de matriz pode ser aplicado a um conjunto de palavras em vez de letras. Sua função deve aplicar isso às palavras em dois textos e retornar o valor LCS normalizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the normalized LCS given an answer text and a source text\n",
    "def lcs_norm_word(answer_text, source_text):\n",
    "    '''Computes the longest common subsequence of words in two texts; returns a normalized value.\n",
    "       :param answer_text: The pre-processed text for an answer text\n",
    "       :param source_text: The pre-processed text for an answer's associated source text\n",
    "       :return: A normalized LCS value'''\n",
    "    \n",
    "    # Creates lists of words from source and answer \n",
    "    answer_list = answer_text.split()\n",
    "    source_list = source_text.split()\n",
    "    \n",
    "    # Makes matrix for dynamic programming\n",
    "    matrix = np.zeros((len(source_list)+1, len(answer_list)+1))\n",
    "    \n",
    "    # Computes lcs\n",
    "    for i, word_i in enumerate(source_list):\n",
    "        for j, word_j in enumerate(answer_list):\n",
    "            if word_i != word_j:\n",
    "                matrix[i+1, j+1] = max(matrix[i+1, j], matrix[i, j+1])\n",
    "            else:\n",
    "                matrix[i+1, j+1] = matrix[i, j] + 1\n",
    "    \n",
    "    return matrix[-1][-1] / len(answer_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Células de teste\n",
    "\n",
    "Vamos começar testando seu código no exemplo dado na descrição inicial.\n",
    "\n",
    "Na célula abaixo, especificamos as strings A (texto de resposta) e S (texto de origem original). Sabemos que esses textos têm 20 palavras em comum e a resposta enviada tem 27 palavras, então a subsequência comum mais longa normalizada deve ser 20/27."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LCS =  0.7407407407407407\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# Run the test scenario from above\n",
    "# does your function return the expected value?\n",
    "\n",
    "A = \"i think pagerank is a link analysis algorithm used by google that uses a system of weights attached to each element of a hyperlinked set of documents\"\n",
    "S = \"pagerank is a link analysis algorithm used by the google internet search engine that assigns a numerical weighting to each element of a hyperlinked set of documents\"\n",
    "\n",
    "# calculate LCS\n",
    "lcs = lcs_norm_word(A, S)\n",
    "print('LCS = ', lcs)\n",
    "\n",
    "\n",
    "# expected value test\n",
    "assert lcs==20/27., \"Incorrect LCS value, expected about 0.7408, got \"+str(lcs)\n",
    "\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next cell runs a more rigorous test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "# run test cell\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test lcs implementation\n",
    "# params: complete_df from before, and lcs_norm_word function\n",
    "tests.test_lcs(complete_df, lcs_norm_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, take a look at a few resultant values for `lcs_norm_word`. Just like before, you should see that higher values correspond to higher levels of plagiarism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test on your own\n",
    "test_indices = range(5) # look at first few files\n",
    "\n",
    "category_vals = []\n",
    "lcs_norm_vals = []\n",
    "# iterate through first few docs and calculate LCS\n",
    "for i in test_indices:\n",
    "    category_vals.append(complete_df.loc[i, 'Category'])\n",
    "    # get texts to compare\n",
    "    answer_text = complete_df.loc[i, 'Text'] \n",
    "    task = complete_df.loc[i, 'Task']\n",
    "    # we know that source texts have Class = -1\n",
    "    orig_rows = complete_df[(complete_df['Class'] == -1)]\n",
    "    orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "    source_text = orig_row['Text'].values[0]\n",
    "    \n",
    "    # calculate lcs\n",
    "    lcs_val = lcs_norm_word(answer_text, source_text)\n",
    "    lcs_norm_vals.append(lcs_val)\n",
    "\n",
    "# print out result, does it make sense?\n",
    "print('Original category values: \\n', category_vals)\n",
    "print()\n",
    "print('Normalized LCS values: \\n', lcs_norm_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Crie todos os recursos\n",
    "\n",
    "Agora que você concluiu as funções de cálculo de recursos, é hora de realmente criar vários recursos e decidir quais usar em seu modelo final! Nas células abaixo, você tem duas funções auxiliares para ajudá-lo a criar vários recursos e armazená-los em um DataFrame, `features_df`.\n",
    "\n",
    "\n",
    "### Criação de vários recursos de contenção\n",
    "\n",
    "Sua função `calcul_containment` completa será chamada na próxima célula, que define a função auxiliar` create_containment_features`.\n",
    "\n",
    "> Esta função retorna uma lista de recursos de contenção, calculada para um dado `n` e para * todos * os arquivos em um df (assumido como` complete_df`).\n",
    "\n",
    "Para nossos arquivos originais, o valor de contenção é definido como um valor especial, -1.\n",
    "\n",
    "Esta função oferece a capacidade de criar facilmente vários recursos de contenção, de diferentes comprimentos de n-gramas, para cada um de nossos arquivos de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function returns a list of containment features, calculated for a given n \n",
    "# Should return a list of length 100 for all files in a complete_df\n",
    "def create_containment_features(df, n, column_name=None):\n",
    "    \n",
    "    containment_values = []\n",
    "    \n",
    "    if(column_name==None):\n",
    "        column_name = 'c_'+str(n) # c_1, c_2, .. c_n\n",
    "    \n",
    "    # iterates through dataframe rows\n",
    "    for i in df.index:\n",
    "        file = df.loc[i, 'File']\n",
    "        # Computes features using calculate_containment function\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            c = calculate_containment(df, n, file)\n",
    "            containment_values.append(c)\n",
    "        # Sets value to -1 for original tasks \n",
    "        else:\n",
    "            containment_values.append(-1)\n",
    "    \n",
    "    print(str(n)+'-gram containment features created!')\n",
    "    return containment_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Criando recursos LCS\n",
    "\n",
    "Abaixo, sua função `lcs_norm_word` completa é usada para criar uma lista de recursos LCS para todos os arquivos de resposta em um determinado DataFrame (novamente, isso pressupõe que você está passando` complete_df`. Ele atribui um valor especial para o nosso fonte original arquivos, -1.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Function creates lcs feature and add it to the dataframe\n",
    "def create_lcs_features(df, column_name='lcs_word'):\n",
    "    \n",
    "    lcs_values = []\n",
    "    \n",
    "    # iterate through files in dataframe\n",
    "    for i in df.index:\n",
    "        # Computes LCS_norm words feature using function above for answer tasks\n",
    "        if df.loc[i,'Category'] > -1:\n",
    "            # get texts to compare\n",
    "            answer_text = df.loc[i, 'Text'] \n",
    "            task = df.loc[i, 'Task']\n",
    "            # we know that source texts have Class = -1\n",
    "            orig_rows = df[(df['Class'] == -1)]\n",
    "            orig_row = orig_rows[(orig_rows['Task'] == task)]\n",
    "            source_text = orig_row['Text'].values[0]\n",
    "\n",
    "            # calculate lcs\n",
    "            lcs = lcs_norm_word(answer_text, source_text)\n",
    "            lcs_values.append(lcs)\n",
    "        # Sets to -1 for original tasks \n",
    "        else:\n",
    "            lcs_values.append(-1)\n",
    "\n",
    "    print('LCS features created!')\n",
    "    return lcs_values\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCÍCIO: Crie um DataFrame de recursos selecionando um `ngram_range`\n",
    "\n",
    "O artigo sugere o cálculo dos seguintes recursos: contenção * 1 grama a 5 gramas * e * subsequência comum mais longa *.\n",
    "> Neste exercício, você pode escolher criar ainda mais recursos, por exemplo de * recursos de contenção de * 1 a 7 gramas * e * subsequência comum mais longa *.\n",
    "\n",
    "Você vai querer criar pelo menos 6 recursos para escolher enquanto pensa sobre quais dar ao seu modelo de classificação final. Definir e comparar pelo menos 6 recursos diferentes permite descartar todos os recursos que parecem redundantes e escolher usar os melhores recursos para seu modelo final!\n",
    "\n",
    "Na célula abaixo **defina um intervalo de n-gramas**; esses serão os n's que você usará para criar recursos de contenção de n-gramas. O restante do código de criação do recurso é fornecido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram containment features created!\n",
      "2-gram containment features created!\n",
      "3-gram containment features created!\n",
      "4-gram containment features created!\n",
      "5-gram containment features created!\n",
      "6-gram containment features created!\n",
      "LCS features created!\n",
      "\n",
      "Features:  ['c_1', 'c_2', 'c_3', 'c_4', 'c_5', 'c_6', 'lcs_word']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define an ngram range\n",
    "ngram_range = range(1,7)\n",
    "\n",
    "\n",
    "# The following code may take a minute to run, depending on your ngram_range\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "features_list = []\n",
    "\n",
    "# Create features in a features_df\n",
    "all_features = np.zeros((len(ngram_range)+1, len(complete_df)))\n",
    "\n",
    "# Calculate features for containment for ngrams in range\n",
    "i=0\n",
    "for n in ngram_range:\n",
    "    column_name = 'c_'+str(n)\n",
    "    features_list.append(column_name)\n",
    "    # create containment features\n",
    "    all_features[i]=np.squeeze(create_containment_features(complete_df, n))\n",
    "    i+=1\n",
    "\n",
    "# Calculate features for LCS_Norm Words \n",
    "features_list.append('lcs_word')\n",
    "all_features[i]= np.squeeze(create_lcs_features(complete_df))\n",
    "\n",
    "# create a features dataframe\n",
    "features_df = pd.DataFrame(np.transpose(all_features), columns=features_list)\n",
    "\n",
    "# Print all features/columns\n",
    "print()\n",
    "print('Features: ', features_list)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.398148</td>\n",
       "      <td>0.079070</td>\n",
       "      <td>0.009346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.191781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.984694</td>\n",
       "      <td>0.964103</td>\n",
       "      <td>0.943299</td>\n",
       "      <td>0.922280</td>\n",
       "      <td>0.901042</td>\n",
       "      <td>0.820755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.869369</td>\n",
       "      <td>0.719457</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>0.515982</td>\n",
       "      <td>0.449541</td>\n",
       "      <td>0.382488</td>\n",
       "      <td>0.846491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.593583</td>\n",
       "      <td>0.268817</td>\n",
       "      <td>0.156757</td>\n",
       "      <td>0.108696</td>\n",
       "      <td>0.081967</td>\n",
       "      <td>0.060440</td>\n",
       "      <td>0.316062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.544503</td>\n",
       "      <td>0.115789</td>\n",
       "      <td>0.031746</td>\n",
       "      <td>0.005319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.329502</td>\n",
       "      <td>0.053846</td>\n",
       "      <td>0.007722</td>\n",
       "      <td>0.003876</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.161172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.590308</td>\n",
       "      <td>0.150442</td>\n",
       "      <td>0.035556</td>\n",
       "      <td>0.004464</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.765306</td>\n",
       "      <td>0.709898</td>\n",
       "      <td>0.664384</td>\n",
       "      <td>0.625430</td>\n",
       "      <td>0.589655</td>\n",
       "      <td>0.553633</td>\n",
       "      <td>0.621711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.759777</td>\n",
       "      <td>0.505618</td>\n",
       "      <td>0.395480</td>\n",
       "      <td>0.306818</td>\n",
       "      <td>0.245714</td>\n",
       "      <td>0.195402</td>\n",
       "      <td>0.484305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.884444</td>\n",
       "      <td>0.526786</td>\n",
       "      <td>0.340807</td>\n",
       "      <td>0.247748</td>\n",
       "      <td>0.180995</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.597458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        c_1       c_2       c_3       c_4       c_5       c_6  lcs_word\n",
       "0  0.398148  0.079070  0.009346  0.000000  0.000000  0.000000  0.191781\n",
       "1  1.000000  0.984694  0.964103  0.943299  0.922280  0.901042  0.820755\n",
       "2  0.869369  0.719457  0.613636  0.515982  0.449541  0.382488  0.846491\n",
       "3  0.593583  0.268817  0.156757  0.108696  0.081967  0.060440  0.316062\n",
       "4  0.544503  0.115789  0.031746  0.005319  0.000000  0.000000  0.242574\n",
       "5  0.329502  0.053846  0.007722  0.003876  0.000000  0.000000  0.161172\n",
       "6  0.590308  0.150442  0.035556  0.004464  0.000000  0.000000  0.301653\n",
       "7  0.765306  0.709898  0.664384  0.625430  0.589655  0.553633  0.621711\n",
       "8  0.759777  0.505618  0.395480  0.306818  0.245714  0.195402  0.484305\n",
       "9  0.884444  0.526786  0.340807  0.247748  0.180995  0.150000  0.597458"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print some results \n",
    "features_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos Correlacionados\n",
    "\n",
    "Você deve usar a correlação de recursos em todo o conjunto de dados * inteiro * para determinar quais recursos são *** muito *** ** altamente correlacionados ** entre si para incluir os dois recursos em um único modelo. Para esta análise, você pode usar o conjunto de dados * inteiro * devido ao pequeno tamanho da amostra que temos.\n",
    "\n",
    "Todos os nossos recursos tentam medir a semelhança entre dois textos. Como nossos recursos são projetados para medir similaridade, espera-se que esses recursos sejam altamente correlacionados. Muitos modelos de classificação, por exemplo, um classificador Naive Bayes, baseiam-se na suposição de que os recursos * não * são altamente correlacionados; recursos altamente correlacionados podem exagerar na importância de um único recurso.\n",
    "\n",
    "Portanto, você desejará escolher seus recursos com base em quais pares têm a correlação mais baixa. Esses valores de correlação variam entre 0 e 1; de baixa para alta correlação e são exibidos em uma [matriz de correlação](https://www.displayr.com/what-is-a-correlation-matrix/), abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>c_1</th>\n",
       "      <th>c_2</th>\n",
       "      <th>c_3</th>\n",
       "      <th>c_4</th>\n",
       "      <th>c_5</th>\n",
       "      <th>c_6</th>\n",
       "      <th>lcs_word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>c_1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.89</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_2</th>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_3</th>\n",
       "      <td>0.90</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_4</th>\n",
       "      <td>0.89</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_5</th>\n",
       "      <td>0.88</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c_6</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.99</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lcs_word</th>\n",
       "      <td>0.97</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           c_1   c_2   c_3   c_4   c_5   c_6  lcs_word\n",
       "c_1       1.00  0.94  0.90  0.89  0.88  0.87      0.97\n",
       "c_2       0.94  1.00  0.99  0.98  0.97  0.96      0.98\n",
       "c_3       0.90  0.99  1.00  1.00  0.99  0.98      0.97\n",
       "c_4       0.89  0.98  1.00  1.00  1.00  0.99      0.95\n",
       "c_5       0.88  0.97  0.99  1.00  1.00  1.00      0.95\n",
       "c_6       0.87  0.96  0.98  0.99  1.00  1.00      0.94\n",
       "lcs_word  0.97  0.98  0.97  0.95  0.95  0.94      1.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# Create correlation matrix for just Features to determine different models to test\n",
    "corr_matrix = features_df.corr().abs().round(2)\n",
    "\n",
    "# display shows all of a dataframe\n",
    "display(corr_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Create selected train/test data\n",
    "\n",
    "Complete the `train_test_data` function below. This function should take in the following parameters:\n",
    "* `complete_df`: A DataFrame that contains all of our processed text data, file info, datatypes, and class labels\n",
    "* `features_df`: A DataFrame of all calculated features, such as containment for ngrams, n= 1-5, and lcs values for each text file listed in the `complete_df` (this was created in the above cells)\n",
    "* `selected_features`: A list of feature column names,  ex. `['c_1', 'lcs_word']`, which will be used to select the final features in creating train/test sets of data.\n",
    "\n",
    "It should return two tuples:\n",
    "* `(train_x, train_y)`, selected training features and their corresponding class labels (0/1)\n",
    "* `(test_x, test_y)`, selected training features and their corresponding class labels (0/1)\n",
    "\n",
    "** Observação: x e y devem ser matrizes de valores de recursos e rótulos de classe numéricos, respectivamente; não DataFrames. **\n",
    "\n",
    "Olhando para a matriz de correlação acima, você deve decidir sobre um valor de correlação de **cutoff**, inferior a 1,0, para determinar quais conjuntos de recursos são * muito * altamente correlacionados para serem incluídos nos dados finais de treinamento e teste. Se você não conseguir encontrar recursos menos correlacionados do que algum valor de corte, sugere-se que aumente o número de recursos (n-gramas mais longos) para escolher ou use * apenas um ou dois * recursos em seu modelo final para evitar a introdução de alta recursos correlacionados.\n",
    "\n",
    "Lembre-se de que o `complete_df` tem uma coluna` Datatype` que indica se os dados devem ser `train` ou` test`; isso deve ajudá-lo a dividir os dados de maneira adequada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Takes in dataframes and a list of selected features (column names) \n",
    "# and returns (train_x, train_y), (test_x, test_y)\n",
    "def train_test_data(complete_df, features_df, selected_features):\n",
    "    '''Gets selected training and test features from given dataframes, and \n",
    "       returns tuples for training and test features and their corresponding class labels.\n",
    "       :param complete_df: A dataframe with all of our processed text data, datatypes, and labels\n",
    "       :param features_df: A dataframe of all computed, similarity features\n",
    "       :param selected_features: An array of selected features that correspond to certain columns in `features_df`\n",
    "       :return: training and test features and labels: (train_x, train_y), (test_x, test_y)'''\n",
    "    \n",
    "    df = pd.concat([complete_df, features_df[selected_features]], axis=1)\n",
    "    is_train = df['Datatype'] == 'train'\n",
    "    is_test = df['Datatype'] == 'test'\n",
    "        \n",
    "    # get the training features\n",
    "    train_x = df[is_train][selected_features].values\n",
    "    # And training class labels (0 or 1)\n",
    "    train_y = df[is_train]['Class'].values\n",
    "    \n",
    "    # get the test features and labels\n",
    "    test_x = df[is_test][selected_features].values\n",
    "    test_y = df[is_test]['Class'].values\n",
    "    \n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cells\n",
    "\n",
    "Below, test out your implementation and create the final train/test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "test_selection = list(features_df)[:2] # first couple columns as a test\n",
    "# test that the correct train/test data is created\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, test_selection)\n",
    "\n",
    "# params: generated train/test data\n",
    "tests.test_data_split(train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCÍCIO: Selecione \"bons\" recursos\n",
    "\n",
    "Se você passou no teste acima, pode criar seus próprios dados de trem / teste abaixo.\n",
    "\n",
    "Defina uma lista de recursos que você gostaria de incluir em seu modo final, `selected_features`; esta é uma lista dos nomes dos recursos que você deseja incluir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size:  70\n",
      "Test size:  25\n",
      "\n",
      "Training df sample: \n",
      " [[0.39814815 0.         0.19178082]\n",
      " [0.86936937 0.44954128 0.84649123]\n",
      " [0.59358289 0.08196721 0.31606218]\n",
      " [0.54450262 0.         0.24257426]\n",
      " [0.32950192 0.         0.16117216]\n",
      " [0.59030837 0.         0.30165289]\n",
      " [0.75977654 0.24571429 0.48430493]\n",
      " [0.51612903 0.         0.27083333]\n",
      " [0.44086022 0.         0.22395833]\n",
      " [0.97945205 0.78873239 0.9       ]]\n"
     ]
    }
   ],
   "source": [
    "# Select your list of features, this should be column names from features_df\n",
    "# ex. ['c_1', 'lcs_word']\n",
    "selected_features = ['c_1', 'c_5', 'lcs_word']\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "(train_x, train_y), (test_x, test_y) = train_test_data(complete_df, features_df, selected_features)\n",
    "\n",
    "# check that division of samples seems correct\n",
    "# these should add up to 95 (100 - 5 original files)\n",
    "print('Training size: ', len(train_x))\n",
    "print('Test size: ', len(test_x))\n",
    "print()\n",
    "print('Training df sample: \\n', train_x[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pergunta 2: Como você decidiu quais recursos incluir em seu modelo final?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Criação de arquivos de dados finais\n",
    "\n",
    "Agora, você está quase pronto para começar a treinar um modelo no SageMaker!\n",
    "\n",
    "Você deseja acessar seus dados de treinamento e teste no SageMaker e enviá-los para o S3. Neste projeto, SageMaker espera o seguinte formato para seus dados de treinamento / teste:\n",
    "* Os dados de treinamento e teste devem ser salvos em um arquivo `.csv` cada, ex` train.csv` e `test.csv`\n",
    "* Esses arquivos devem ter rótulos de classe na primeira coluna e recursos no resto das colunas\n",
    "\n",
    "Este formato segue a prática, descrita na [documentação do SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/cdf-training.html), que diz: \"Amazon SageMaker requer que um arquivo CSV não tem um registro de cabeçalho e que a variável de destino [rótulo de classe] está na primeira coluna. \"\n",
    "\n",
    "## EXERCÍCIO: Crie arquivos csv\n",
    "\n",
    "Defina uma função que receba x (recursos) e y (rótulos) e os salve em um arquivo `.csv` no caminho` data_dir / filename`.\n",
    "\n",
    "Pode ser útil usar o pandas para mesclar seus recursos e rótulos em um DataFrame e depois convertê-lo em um arquivo csv. Você pode ter certeza de se livrar de quaisquer linhas incompletas, em um DataFrame, usando `dropna`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(x, y, filename, data_dir):\n",
    "    '''Merges features and labels and converts them into one csv file with labels in the first column.\n",
    "       :param x: Data features\n",
    "       :param y: Data labels\n",
    "       :param file_name: Name of csv file, ex. 'train.csv'\n",
    "       :param data_dir: The directory where files will be saved\n",
    "       '''\n",
    "    # make data dir, if it does not exist\n",
    "    if not os.path.exists(data_dir):\n",
    "        os.makedirs(data_dir)\n",
    "    \n",
    "    # save data in csv file\n",
    "    df = pd.concat([pd.DataFrame(y), pd.DataFrame(x)], axis=1)\n",
    "    df.to_csv(os.path.join(data_dir, filename), header=False, index=False)\n",
    "        \n",
    "    # nothing is returned, but a print statement indicates that the function has run\n",
    "    print('Path created: '+str(data_dir)+'/'+str(filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Células de teste\n",
    "\n",
    "Teste se seu código produz o formato correto para um arquivo `.csv`, dados alguns recursos de texto e rótulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: test_csv/to_delete.csv\n",
      "Tests passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "fake_x = [ [0.39814815, 0.0001, 0.19178082], \n",
    "           [0.86936937, 0.44954128, 0.84649123], \n",
    "           [0.44086022, 0., 0.22395833] ]\n",
    "\n",
    "fake_y = [0, 1, 1]\n",
    "\n",
    "make_csv(fake_x, fake_y, filename='to_delete.csv', data_dir='test_csv')\n",
    "\n",
    "# read in and test dimensions\n",
    "fake_df = pd.read_csv('test_csv/to_delete.csv', header=None)\n",
    "\n",
    "# check shape\n",
    "assert fake_df.shape==(3, 4), \\\n",
    "      'The file should have as many rows as data_points and as many columns as features+1 (for indices).'\n",
    "# check that first column = labels\n",
    "assert np.all(fake_df.iloc[:,0].values==fake_y), 'First column is not equal to the labels, fake_y.'\n",
    "print('Tests passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' nÆo ‚ reconhecido como um comando interno\n",
      "ou externo, um programa oper vel ou um arquivo em lotes.\n"
     ]
    }
   ],
   "source": [
    "# delete the test csv file, generated above\n",
    "! rm -rf test_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você passou nos testes acima, execute a seguinte célula para criar os arquivos `train.csv` e` test.csv` em um diretório que você especificar! Isso salvará os dados em um diretório local. Lembre-se do nome deste diretório porque você o fará referência novamente ao enviar esses dados para o S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path created: plagiarism_data/train.csv\n",
      "Path created: plagiarism_data/test.csv\n"
     ]
    }
   ],
   "source": [
    "# can change directory, if you want\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "make_csv(train_x, train_y, filename='train.csv', data_dir=data_dir)\n",
    "make_csv(test_x, test_y, filename='test.csv', data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A seguir\n",
    "\n",
    "Agora que você fez a engenharia de recursos e criou alguns dados de treinamento e teste, está pronto para treinar e implantar um modelo de classificação de plágio. O próximo notebook utilizará os recursos do SageMaker para treinar e testar um modelo que você projeta."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
